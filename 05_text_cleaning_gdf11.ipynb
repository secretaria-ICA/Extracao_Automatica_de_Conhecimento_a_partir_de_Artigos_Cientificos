{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajurberg/article-parser/blob/main/05_text_cleaning_gdf11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gDCcelfMqTz"
      },
      "outputs": [],
      "source": [
        "############################# \n",
        "#@title Installation of libraries \n",
        "#############################\n",
        "import os\n",
        "from time import time\n",
        "import re, string, unicodedata\n",
        "from string import punctuation\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-7T2rGbMZx-",
        "outputId": "4caeda26-c719-4988-ab57-6b1f5bad85f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "############################# \n",
        "#@title Mounting Google Drive\n",
        "#############################\n",
        "from google.colab import drive\n",
        "drive._mount('/content/drive')\n",
        "\n",
        "import os\n",
        "workdir_path = '/content/drive/My Drive/papers'\n",
        "os.chdir(workdir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0SqGqCxNV4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cd275c-192a-4971-c85b-87ce850a1e82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "334"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "############################# \n",
        "#@title Read json file to dictionary\n",
        "#############################\n",
        "import json\n",
        "\n",
        "with open(\"gdf11-dictionary.json\") as json_file:\n",
        "  gdf11_dict = json.load(json_file)\n",
        "\n",
        "len(gdf11_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTtt7CZOKuxD"
      },
      "outputs": [],
      "source": [
        "############################# \n",
        "#@title Text preprocessing\n",
        "#############################\n",
        "\n",
        "def find_between(s, first, last):\n",
        "  try:\n",
        "    start = s.index(first) + len(first)\n",
        "    end = s.index(last, start)\n",
        "    return s[start:end]\n",
        "  except ValueError:\n",
        "    return \"\"\n",
        "\n",
        "def cleaning_text(string):\n",
        "  string = string.lower()\n",
        "  string = string.strip().replace(\"\\n\", ' ')\n",
        "  string = string.strip().replace('\\t', ' ')\n",
        "  string = string.strip().replace(r\"\\u\", ' ')\n",
        "  string = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', \"\", string) # removes e-mails\n",
        "  string = re.sub(\"(fig. \\d+)\", \"\", string)\n",
        "  string = string.strip().replace('®', '')\n",
        "  string = re.sub(\"•\", \"\", string)\n",
        "  string = re.sub(\"\\*\", \"\", string)\n",
        "  string = re.sub(\"·\", \"\", string)\n",
        "  string = re.sub(\"�+\", \" \", string)\n",
        "  string = re.sub(\"● ▶+\", \"\", string)\n",
        "  string = re.sub(\"\\[(\\d*?)\\]+\", \"\", string) # replaces digits between brackets\n",
        "  string = re.sub(\"\\((\\d*?)\\)+\", \"\", string) # replaces digits between parentheses (and also the parentheses)\n",
        "  string = re.sub(\"(https?://|)[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\", \"\", string) # Removes urls\n",
        "  string = re.sub('\\b\\w{1,2}\\b', '', string) # removes words =< 2 characters\n",
        "  string = re.sub(' +', ' ', string) # replaces multiple consecutive white spaces\n",
        "  string = string.strip().replace(\"- \", \"\")\n",
        "  return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdT2wNIVAbzS"
      },
      "outputs": [],
      "source": [
        "# Denoise text\n",
        "def strip_html(text):\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  return soup.get_text()\n",
        "\n",
        "# Removing URLs\n",
        "def remove_url(text):\n",
        "  return re.sub(r'http\\S+', '', text)\n",
        "\n",
        "# Removing the noisy text\n",
        "def denoise_text(text):\n",
        "  text = strip_html(text)\n",
        "  text = remove_url(text)\n",
        "  text = text.strip().replace(\"- \", \"\")\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FSeFkH3Nt51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02acf2f3-9a99-4091-b7b0-04a2c0554078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "############################# \n",
        "#@title NLTK and stopwords\n",
        "#############################\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "doZ1l_VhS-A4",
        "outputId": "833d375f-0849-4a46-fc8d-d0c29613c075"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3e35bbd3-461d-47ac-b87e-5fe03f231555\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PMID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Citation</th>\n",
              "      <th>First Author</th>\n",
              "      <th>Journal/Book</th>\n",
              "      <th>Publication Year</th>\n",
              "      <th>Create Date</th>\n",
              "      <th>PMCID</th>\n",
              "      <th>NIHMS ID</th>\n",
              "      <th>DOI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34951250</td>\n",
              "      <td>[Preliminary study on cerebrospinal fluid prot...</td>\n",
              "      <td>Li HZ, Zeng NX, Liu KG, Luo WL, Lu WJ, Wu LL.</td>\n",
              "      <td>Zhongguo Zhong Yao Za Zhi. 2021 Dec;46(23):623...</td>\n",
              "      <td>Li HZ</td>\n",
              "      <td>Zhongguo Zhong Yao Za Zhi</td>\n",
              "      <td>2021</td>\n",
              "      <td>2021/12/24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.19540/j.cnki.cjcmm.20210918.401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34905649</td>\n",
              "      <td>Growth differentiation factor 11 accelerates l...</td>\n",
              "      <td>Sun J, Li Y, Yang X, Dong W, Yang J, Hu Q, Zha...</td>\n",
              "      <td>Aging Cell. 2021 Dec 14:e13532. doi: 10.1111/a...</td>\n",
              "      <td>Sun J</td>\n",
              "      <td>Aging Cell</td>\n",
              "      <td>2021</td>\n",
              "      <td>2021/12/14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1111/acel.13532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34809067</td>\n",
              "      <td>Detection of GDF11 by using a Ti(3)C(2)-MXene-...</td>\n",
              "      <td>Liu C, Wang R, Shao Y, Chen C, Wu P, Wei Y, Ga...</td>\n",
              "      <td>Opt Express. 2021 Oct 25;29(22):36598-36607. d...</td>\n",
              "      <td>Liu C</td>\n",
              "      <td>Opt Express</td>\n",
              "      <td>2021</td>\n",
              "      <td>2021/11/23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1364/OE.440585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34791251</td>\n",
              "      <td>Gonadal rejuvenation of mice by GDF11</td>\n",
              "      <td>Zhou Y, Ni S, Li C, Song L, Zhang S.</td>\n",
              "      <td>J Gerontol A Biol Sci Med Sci. 2021 Nov 13:gla...</td>\n",
              "      <td>Zhou Y</td>\n",
              "      <td>J Gerontol A Biol Sci Med Sci</td>\n",
              "      <td>2021</td>\n",
              "      <td>2021/11/18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1093/gerona/glab343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34712387</td>\n",
              "      <td>GDF-11 Protects the Traumatically Injured Spin...</td>\n",
              "      <td>Xu Y, Hu X, Li F, Zhang H, Lou J, Wang X, Wang...</td>\n",
              "      <td>Oxid Med Cell Longev. 2021 Oct 19;2021:8186877...</td>\n",
              "      <td>Xu Y</td>\n",
              "      <td>Oxid Med Cell Longev</td>\n",
              "      <td>2021</td>\n",
              "      <td>2021/10/29</td>\n",
              "      <td>PMC8548157</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1155/2021/8186877</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e35bbd3-461d-47ac-b87e-5fe03f231555')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e35bbd3-461d-47ac-b87e-5fe03f231555 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e35bbd3-461d-47ac-b87e-5fe03f231555');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       PMID  ...                                 DOI\n",
              "0  34951250  ...  10.19540/j.cnki.cjcmm.20210918.401\n",
              "1  34905649  ...                  10.1111/acel.13532\n",
              "2  34809067  ...                   10.1364/OE.440585\n",
              "3  34791251  ...              10.1093/gerona/glab343\n",
              "4  34712387  ...                10.1155/2021/8186877\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Read csv file - I'll get info that will be used as stopwords\n",
        "df = pd.read_csv(\"2022-01-05_csv-gdf11-set.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHn9NZaNTvPa",
        "outputId": "100dbcfa-da69-48a8-ad1a-94cb540b13e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List size: 1600\n"
          ]
        }
      ],
      "source": [
        "# To generate a list of author names (will be used as stopwords later)\n",
        "authors = []\n",
        "for author in df.Authors:\n",
        "  author = author.lower().strip().split(\",\")\n",
        "  for name in author:\n",
        "    name = name.split(\" \")\n",
        "    for n in name:\n",
        "      n = n.strip().replace(\".\", \"\")\n",
        "      if len(n) <= 2 or n in authors:\n",
        "        pass\n",
        "      else:\n",
        "        authors.append(n)      \n",
        "\n",
        "print(f\"List size: {len(authors)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvUfOP1RXoJ6",
        "outputId": "2117c3d5-502a-4df7-bb55-f9a2faaa2740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List size: 256\n"
          ]
        }
      ],
      "source": [
        "# To generate a list of Journal/Book (will be used as stopwords later)\n",
        "journals = []\n",
        "for journal in df['Journal/Book']:\n",
        "  journal = journal.lower().strip()\n",
        "  # since 'development' is also an important noun, I removed it from going into the list\n",
        "  if journal == \"development\" or journal in journals:\n",
        "    pass\n",
        "  else:\n",
        "    journals.append(journal)\n",
        "\n",
        "print(f\"List size: {len(journals)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6999894c-151c-4e43-be73-7bbe69ef252a",
        "id": "rSTMTdfmltBA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List size: 2549 words\n"
          ]
        }
      ],
      "source": [
        "# Stopwords from stopwords-json\n",
        "stopwords_json = {\"en\":[\"a\",\"a's\",\"able\",\"about\",\"above\",\"according\",\"accordingly\",\"across\",\"actually\",\"after\",\"afterwards\",\"again\",\"against\",\"ain't\",\"all\",\"allow\",\"allows\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\"among\",\"amongst\",\"an\",\"and\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"are\",\"aren't\",\"around\",\"as\",\"aside\",\"ask\",\"asking\",\"associated\",\"at\",\"available\",\"away\",\"awfully\",\"b\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"becoming\",\"been\",\"before\",\"beforehand\",\"behind\",\"being\",\"believe\",\"below\",\"beside\",\"besides\",\"best\",\"better\",\"between\",\"beyond\",\"both\",\"brief\",\"but\",\"by\",\"c\",\"c'mon\",\"c's\",\"came\",\"can\",\"can't\",\"cannot\",\"cant\",\"cause\",\"causes\",\"certain\",\"certainly\",\"changes\",\"clearly\",\"co\",\"com\",\"come\",\"comes\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"contain\",\"containing\",\"contains\",\"corresponding\",\"could\",\"couldn't\",\"course\",\"currently\",\"d\",\"definitely\",\"described\",\"despite\",\"did\",\"didn't\",\"different\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"done\",\"down\",\"downwards\",\"during\",\"e\",\"each\",\"edu\",\"eg\",\"eight\",\"either\",\"else\",\"elsewhere\",\"enough\",\"entirely\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"exactly\",\"example\",\"except\",\"f\",\"far\",\"few\",\"fifth\",\"first\",\"five\",\"followed\",\"following\",\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"four\",\"from\",\"further\",\"furthermore\",\"g\",\"get\",\"gets\",\"getting\",\"given\",\"gives\",\"go\",\"goes\",\"going\",\"gone\",\"got\",\"gotten\",\"greetings\",\"h\",\"had\",\"hadn't\",\"happens\",\"hardly\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he's\",\"hello\",\"help\",\"hence\",\"her\",\"here\",\"here's\",\"hereafter\",\"hereby\",\"herein\",\"hereupon\",\"hers\",\"herself\",\"hi\",\"him\",\"himself\",\"his\",\"hither\",\"hopefully\",\"how\",\"howbeit\",\"however\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"ie\",\"if\",\"ignored\",\"immediate\",\"in\",\"inasmuch\",\"inc\",\"indeed\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"instead\",\"into\",\"inward\",\"is\",\"isn't\",\"it\",\"it'd\",\"it'll\",\"it's\",\"its\",\"itself\",\"j\",\"just\",\"k\",\"keep\",\"keeps\",\"kept\",\"know\",\"known\",\"knows\",\"l\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"let's\",\"like\",\"liked\",\"likely\",\"little\",\"look\",\"looking\",\"looks\",\"ltd\",\"m\",\"mainly\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"meanwhile\",\"merely\",\"might\",\"more\",\"moreover\",\"most\",\"mostly\",\"much\",\"must\",\"my\",\"myself\",\"n\",\"name\",\"namely\",\"nd\",\"near\",\"nearly\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"no\",\"nobody\",\"non\",\"none\",\"noone\",\"nor\",\"normally\",\"not\",\"nothing\",\"novel\",\"now\",\"nowhere\",\"o\",\"obviously\",\"of\",\"off\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"on\",\"once\",\"one\",\"ones\",\"only\",\"onto\",\"or\",\"other\",\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\"over\",\"overall\",\"own\",\"p\",\"particular\",\"particularly\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"possible\",\"presumably\",\"probably\",\"provides\",\"q\",\"que\",\"quite\",\"qv\",\"r\",\"rather\",\"rd\",\"re\",\"really\",\"reasonably\",\"regarding\",\"regardless\",\"regards\",\"relatively\",\"respectively\",\"right\",\"s\",\"said\",\"same\",\"saw\",\"say\",\"saying\",\"says\",\"second\",\"secondly\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sensible\",\"sent\",\"serious\",\"seriously\",\"seven\",\"several\",\"shall\",\"she\",\"should\",\"shouldn't\",\"since\",\"six\",\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specified\",\"specify\",\"specifying\",\"still\",\"sub\",\"such\",\"sup\",\"sure\",\"t\",\"t's\",\"take\",\"taken\",\"tell\",\"tends\",\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that's\",\"thats\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"there\",\"there's\",\"thereafter\",\"thereby\",\"therefore\",\"therein\",\"theres\",\"thereupon\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"think\",\"third\",\"this\",\"thorough\",\"thoroughly\",\"those\",\"though\",\"three\",\"through\",\"throughout\",\"thru\",\"thus\",\"to\",\"together\",\"too\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"twice\",\"two\",\"u\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlikely\",\"until\",\"unto\",\"up\",\"upon\",\"us\",\"use\",\"used\",\"useful\",\"uses\",\"using\",\"usually\",\"uucp\",\"v\",\"value\",\"various\",\"very\",\"via\",\"viz\",\"vs\",\"w\",\"want\",\"wants\",\"was\",\"wasn't\",\"way\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"welcome\",\"well\",\"went\",\"were\",\"weren't\",\"what\",\"what's\",\"whatever\",\"when\",\"whence\",\"whenever\",\"where\",\"where's\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whither\",\"who\",\"who's\",\"whoever\",\"whole\",\"whom\",\"whose\",\"why\",\"will\",\"willing\",\"wish\",\"with\",\"within\",\"without\",\"won't\",\"wonder\",\"would\",\"wouldn't\",\"x\",\"y\",\"yes\",\"yet\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"z\",\"zero\"]}\n",
        "stopwords_json_en = set(stopwords_json['en'])\n",
        "stopwords_nltk_en_mod = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "#stopwords_punct = set(punctuation)\n",
        "\n",
        "# Combine the stopwords\n",
        "stop = set.union(stopwords_json_en, stopwords_nltk_en_mod) # stopwords_punct\n",
        "\n",
        "# Add new stopwords - just include new stopwords in the list as needed\n",
        "new_stops = [\n",
        "             \"manuscript\", \"articles\", \"article\", \"author\", \"authors\", \"et al.\", \"al.\", \"doi\", \"doi:\", \"print\", \"online\", \"journal\",\n",
        "             \"title\", \"abstract\", \"introduction\", \"materials\", \"methods\", \"results\", \"discussion\", \"acknowledgements\",\n",
        "             \"funding\", \"references\", \"review\", \"letter\", \"commentary\", \"supplementary material\",\n",
        "             \"figures\", \"figure\", \"fig\", \"page\", \"pages\",\"volume\", \"vol.\", \"vol.:\", \"untitled\", \"tables\", \"table\", \n",
        "             \"january\", \"february\",\"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\",\"october\",\"november\",\"december\",\n",
        "             \"suggest\", \"may\", \"within\", \"thus\", \"med\", \"whether\", \"transl\", \"also\", \"correspondence\", \"to\",\n",
        "             \"science journals\", \"aaas\", \"eaat3504\", \"microsoft\", \"sci-hub\", \"e-mail:\", \"grant\", \"grants\",\n",
        "             \"copyright\", \"accepted\", \"publication\", \"full peer\" \"copyediting\", \"typesetting\", \"pagination\", \"proofreading\",\n",
        "             \"©\", \"society\", \"rights\", \"data shown\", \"subscriptions\", \"reprints\", \"document\", \"permission\", \"permissions\", \"request\", \"requests\", \"requested\",\n",
        "             \"web\", \"services\", \"office\", \"published\", \"click\", \"rightslink\", \"editorial\", \"protected copyright\", \"protected copyright reserved\",\n",
        "             \"word\", \"307521dr1_pap_10_21_15\", \"10.1161/circresaha.115.307521\", \"addressed\", \"to\", \"id\",\n",
        "             \"roche\", \"invitrogen\"\n",
        "             ]\n",
        "\n",
        "# Add new stop words to stop\n",
        "for n in new_stops:\n",
        "  stop.add(n)\n",
        "\n",
        "# Add author names to stop\n",
        "for a in authors:\n",
        "  stop.add(a)\n",
        "\n",
        "# Add journal names to stop\n",
        "for j in journals:\n",
        "  stop.add(j)\n",
        "\n",
        "print(f\"List size: {len(stop)} words\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To count how many times the words 'introduction' and 'references' appear in each paper\n",
        "counter = {}\n",
        "for key, text in tqdm(gdf11_dict.items()):\n",
        "  # Creates a 'counter' dictionary of keys to values == 0\n",
        "  counter[key] = dict.fromkeys([\"introduction\", \"references\"], 0)\n",
        "  text = cleaning_text(text)\n",
        "  if \"introduction\" in text:\n",
        "    counter[key]['introduction'] += 1\n",
        "  if \"references\" in text:\n",
        "    counter[key]['references'] += 1\n",
        "\n",
        "counter_df = pd.DataFrame.from_dict(counter).T\n",
        "counter_df.head()\n",
        "counter_df.to_excel(\"counter.xlsx\")\n",
        "\n",
        "# 232 papers have both words 'introduction' and 'references' (69.25%)\n",
        "# 239 papers have the word 'introduction' (71.34%)\n",
        "# 300 papers have the word 'references' (89.55%)\n",
        "# Conclusion: it makes sense to use find_between() function, but I also have to consider the remaining papers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "RwtxZaogUf-K",
        "outputId": "302c4fad-80c2-4291-b179-2a83976b6c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:03<00:00, 100.42it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-af83af10-d2a7-4286-a8ef-c56ce4169d1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>introduction</th>\n",
              "      <th>references</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10320</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dbio.1998.9191</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dbio.2000.9926</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CIRCRESAHA.115.307521</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AD.2019.0610</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af83af10-d2a7-4286-a8ef-c56ce4169d1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af83af10-d2a7-4286-a8ef-c56ce4169d1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af83af10-d2a7-4286-a8ef-c56ce4169d1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       introduction  references\n",
              "10320                             0           0\n",
              "dbio.1998.9191                    1           1\n",
              "dbio.2000.9926                    1           1\n",
              "CIRCRESAHA.115.307521             1           1\n",
              "AD.2019.0610                      0           1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnnJfxdGNslI",
        "outputId": "6e583431-527e-4597-ec77-51add5d47b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:04<00:00, 75.59it/s]\n"
          ]
        }
      ],
      "source": [
        "# To create a dictionary with cleaned texts\n",
        "cleaned_dict = {}\n",
        "for key, text in tqdm(gdf11_dict.items()):\n",
        "  text = cleaning_text(text)\n",
        "  text = denoise_text(text)\n",
        "  if \"introduction\" in text and \"references\" in text:\n",
        "    cleaned_dict[key] = find_between(text, \"introduction\", \"references\") # Get text between 'introduction and 'references'\n",
        "  if \"introduction\" not in text and \"references\" in text:\n",
        "    cleaned_dict[key] = text.partition(\"references\")[0] # Get text before 'references'\n",
        "  else:\n",
        "    cleaned_dict[key] = text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To remove stopwords\n",
        "cleaned_dict_stop = {}\n",
        "for key, text in tqdm(cleaned_dict.items()):\n",
        "  text = \" \".join([word for word in text.split(\" \") if word not in stop])\n",
        "  cleaned_dict_stop[key] = text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbfk1U7O1dqA",
        "outputId": "12af9000-b0ca-4fea-e0be-15d64cdf47ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:00<00:00, 558.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################# \n",
        "#@title Sentence tokenization\n",
        "#############################\n",
        "\n",
        "# To create a dictionary with tokenized sentences\n",
        "sent_dict = {}\n",
        "for key, text in tqdm(cleaned_dict.items()):\n",
        "  sent_dict[key] = sent_tokenize(text)\n",
        "\n",
        "# Save dictionary to json file\n",
        "gdf11_sent = open(\"gdf11-dictionary-sent-tokens.json\", \"w\")\n",
        "json.dump(sent_dict, gdf11_sent)\n",
        "gdf11_sent.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7REmCzzQnMRS",
        "outputId": "9d89dd98-65e2-428f-bf85-6f58676adea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:06<00:00, 48.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To create a dictionary with tokenized sentences without stopwords\n",
        "sent_dict_stop = {}\n",
        "for key, text in tqdm(cleaned_dict_stop.items()):\n",
        "  sent_dict_stop[key] = sent_tokenize(text)\n",
        "\n",
        "# Save dictionary to json file\n",
        "gdf11_sent_stop = open(\"gdf11-dictionary-sent-tokens-stop.json\", \"w\")\n",
        "json.dump(sent_dict_stop, gdf11_sent_stop)\n",
        "gdf11_sent_stop.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssBAD7cLt6ef",
        "outputId": "fb40e7f8-7cde-4bdd-e3bc-9b1454f33a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:06<00:00, 49.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################# \n",
        "#@title Word tokenization\n",
        "#############################\n",
        "\n",
        "# To create a dictionary with tokenized words\n",
        "word_dict = {}\n",
        "for key, text in tqdm(cleaned_dict.items()):\n",
        "  word_dict[key] = word_tokenize(text)\n",
        "\n",
        "# Save dictionary to json file\n",
        "gdf11_word = open(\"gdf11-dictionary-word-tokens.json\", \"w\")\n",
        "json.dump(word_dict, gdf11_word)\n",
        "gdf11_word.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7jlxXRzpKs0",
        "outputId": "ca804494-8175-4c14-cf0e-a08755273a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:24<00:00, 13.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To create a dictionary with tokenized words without stopwords\n",
        "word_dict_stop = {}\n",
        "for key, text in tqdm(cleaned_dict_stop.items()):\n",
        "  word_dict_stop[key] = word_tokenize(text)\n",
        "\n",
        "# Save dictionary to json file\n",
        "gdf11_word_stop = open(\"gdf11-dictionary-word-tokens-stop.json\", \"w\")\n",
        "json.dump(word_dict_stop, gdf11_word_stop)\n",
        "gdf11_word_stop.close()"
      ],
      "metadata": {
        "id": "Qspn4HmhqRhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ba1ff0-89da-4d02-d429-ae7d2e406b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:20<00:00, 15.92it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "05_text-cleaning-gdf11.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPLe/BLFaAY/u09Jny1uaee",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}